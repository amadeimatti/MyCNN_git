{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "# Installing Theano\n",
    "# pip install --upgrade --no-deps git+git://github.com/Theano/Theano.git\n",
    "\n",
    "# Installing Tensorflow\n",
    "# pip install tensorflow\n",
    "\n",
    "# Installing Keras\n",
    "# pip install --upgrade keras\n",
    "\n",
    "# Part 1 - Building the CNN\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Conv2D(64, (3, 3), input_shape = (224, 224, 3), activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 64, activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import cv2\n",
    "from cv2 import imread\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "image_list = []\n",
    "count=0\n",
    "class1_path =\"/path1\"\n",
    "for filename in glob.glob(class1_path): #assuming gif\n",
    "    if count<1000:\n",
    "        #test_image = image.load_img(filename, target_size = (224, 224,3))\n",
    "        #test_image = image.img_to_array(test_image)\n",
    "        #test_image = np.expand_dims(test_image, axis = 0)\n",
    "        im=imread(filename)\n",
    "        \n",
    "        image_list.append(im)\n",
    "        count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tred_list=[]\n",
    "class2_path =\"/path2\"\n",
    "\n",
    "\n",
    "count=0\n",
    "for filename in glob.glob(class2_path): #assuming gif\n",
    "    if count<1000:\n",
    "        #im=imread(filename)\n",
    "        #test_image = image.load_img(filename, target_size = (224, 224,3))\n",
    "        #test_image = image.img_to_array(test_image)\n",
    "        #test_image = np.expand_dims(test_image, axis = 0)\n",
    "        im=imread(filename)\n",
    "        tred_list.append(im)\n",
    "        count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_net=[]\n",
    "for i in range(0,1001):\n",
    "    y_train_net.append(1)\n",
    "for i in range(1001,2001):\n",
    "    y_train_net.append(0)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy\n",
    "\n",
    "def normalizeMatrix(image_resize):\n",
    "    img_a = image_resize[:, :, 0]\n",
    "    img_b = image_resize[:, :, 1]\n",
    "    img_c = image_resize[:, :, 2]  # Extracting single channels from 3 channel image\n",
    "    # The above code could also be replaced with cv2.split(img) << which will return 3 numpy arrays (using opencv)\n",
    "\n",
    "    # normalizing per channel data:\n",
    "    \n",
    "    img_a = MinMaxScaler().fit_transform(img_a)\n",
    "    img_b = MinMaxScaler().fit_transform(img_b)\n",
    "\n",
    "    img_c = MinMaxScaler().fit_transform(img_c)\n",
    "\n",
    "    # putting the 3 channels back together:\n",
    "    img_norm = numpy.empty((224, 224, 3), dtype=numpy.float32)\n",
    "    img_norm[:, :, 0] = img_a\n",
    "    img_norm[:, :, 1] = img_b\n",
    "    img_norm[:, :, 2] = img_c\n",
    "    return img_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_norm=[]\n",
    "for i in range(0,len(image_resize)):\n",
    "    image_norm.append(normalizeMatrix(image_resize[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "treD_norm=[]\n",
    "for i in range(0,len(treD_resize)):\n",
    "    treD_norm.append(normalizeMatrix(treD_resize[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        ..., \n",
       "        [ 0.11320755,  0.        ,  0.11764706],\n",
       "        [ 1.        ,  0.        ,  0.85714287],\n",
       "        [ 0.83333331,  0.71428573,  1.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        ..., \n",
       "        [ 0.        ,  0.04040404,  0.        ],\n",
       "        [ 0.375     ,  1.        ,  0.5       ],\n",
       "        [ 0.        ,  1.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        ..., \n",
       "        [ 1.        ,  0.94444442,  0.94117647],\n",
       "        [ 0.58333331,  0.89830506,  1.        ],\n",
       "        [ 0.83333331,  0.35714287,  0.94444442]],\n",
       "\n",
       "       ..., \n",
       "       [[ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        ..., \n",
       "        [ 0.41509435,  0.969697  ,  0.56862748],\n",
       "        [ 0.41666666,  0.96610171,  0.5714286 ],\n",
       "        [ 0.58333331,  0.64285713,  0.55555558]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        ..., \n",
       "        [ 0.41509435,  0.969697  ,  0.56862748],\n",
       "        [ 0.41666666,  0.96610171,  0.5714286 ],\n",
       "        [ 0.58333331,  0.64285713,  0.55555558]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        ..., \n",
       "        [ 0.41509435,  0.969697  ,  0.56862748],\n",
       "        [ 0.41666666,  0.96610171,  0.5714286 ],\n",
       "        [ 0.58333331,  0.64285713,  0.55555558]]], dtype=float32)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treD_norm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_resize =[]\n",
    "for k in range (0,len(image_list)):\n",
    "    image_resize.append(cv2.resize(image_list[k],(224, 224)).reshape(224,224,3))\n",
    "\n",
    "treD_resize=[]\n",
    "for k in range (0,len(tred_list)):\n",
    "    treD_resize.append(cv2.resize(tred_list[k],(224, 224)).reshape(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_net=[]\n",
    "for i in range (0,1000):\n",
    "    x_train_net.append(image_norm[i])\n",
    "for i in range (0,1000):\n",
    "    x_train_net.append(treD_norm[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_net=y_train_net[0:2000]\n",
    "len(y_train_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( x_train_net, y_train_net, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_trainNumpy=np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_trainNumpy[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.fit(X_trainNumpy,y_train,batch_size=32,\n",
    "                         epochs = 100,\n",
    "               validation_data=None\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_testNumpy=np.array(X_test)\n",
    "scores = model1.evaluate(X_testNumpy, y_test, verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model1= load_model('path_to_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predictImage(imagePath,model1):\n",
    "    im=imread(imagePath)\n",
    "    image_resize=cv2.resize(im,(224, 224)).reshape(224,224,3)\n",
    "    image_norm =normalizeMatrix(image_resize)\n",
    "    result = classifier.predict(cv2.resize(image_norm,(224, 224)).reshape(1,224,224,3))\n",
    "    if result[0][0] == 1:\n",
    "        prediction = \"classe1\"\n",
    "    else:\n",
    "        prediction = 'classe2'\n",
    "    return prediction\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print predictImage(\"/path_to_test\",model1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
